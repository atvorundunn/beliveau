# -*- coding: utf-8 -*-
"""
Created on Tue Feb 26 18:13:54 2019

@author: alisa
"""
import numpy as np
import h5py
import pandas as pd

from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.datasets.samples_generator import make_blobs
from sklearn.preprocessing import StandardScaler

with h5py.File('/Users/tvorua/Downloads/chr8-1_018_locs_render_arender.hdf5', 'r') as data:
    ls = list(data.keys())    
    locs = data.get('locs')
    x = locs['x'] #spcial x coordinates
    x = x[:6000]
    y = locs['y'] #spacial y coordiantes
    y = y[:6000]
    frames = locs['frame'] #temporal data
    #photons = locs['photons']
    #sx = locs['sx']
    #sy = locs['sy']
    #bg = locs['bg']
    #lpx = locs['lpx']
    #lpy = locs['lpy']
    #ellipticity = locs['ellipticity']
    #net_gradient = locs['net_gradient']
    #z = locs['z']
    #d_zcalib = locs['d_zcalib']
    
    
    xy = np.vstack((x, y)).T


# initializing dbscan, fit to data and create clusters
db = DBSCAN(eps=65, min_samples=.001).fit(xy) #fit data from hdf5 file

labels = db.labels_

print(list(zip(labels, xy))



#f = np.fft.fft(labels)
        
        
    #photons = locs['photons']
    #sx = locs['sx']
    #sy = locs['sy']
    #bg = locs['bg']
    #lpx = locs['lpx']
    #lpy = locs['lpy']
    #ellipticity = locs['ellipticity']
    #net_gradient = locs['net_gradient']
    #z = locs['z']
    #d_zcalib = locs['d_zcalib']
    

